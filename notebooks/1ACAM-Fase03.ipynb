{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Esse caderno tem por objetivo a criação de um modelo básico de treinamento, utilizando classificadores lineares, que faça a predição de homologação de arquivamentos de procedimentos enviados à 1A.CAM do MPF.\n",
    "\n",
    "Nesse modelo vamos passar a considerar os textos das íntegras das peças de promoção de arquivamento.\n",
    "\n",
    "**Nota**: os dados desse modelo foram recuperados de procedimentos que tiveram suas deliberações realizadas após o dia 02/07/2018, data em que a nova composição tomou posse na 1A.CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de dados e pré-processamento\n",
    "\n",
    "Vamos fazer a carga dos dados.\n",
    "\n",
    "Vamos ler os textos das íntegras, limpá-los e associar ao dataframe com os dados de homologação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# carga dos textos\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = stopwords.words('portuguese')\n",
    "stop_words.extend(['n', 'nº', 'n°', 'n.º', ',', '.', '!', '?', ';', ':', '...', 'º', '–', '/', '(', ')'])\n",
    "\n",
    "def get_text(file):\n",
    "    with open(file, encoding='utf-8', errors='replace') as f:\n",
    "        data=' '.join(line.strip() for line in f)\n",
    "        f.close()\n",
    "    \n",
    "    return data.strip()\n",
    "\n",
    "def get_text_non_stop_words(text):\n",
    "    filtered_text = ''\n",
    "    for w in word_tokenize(text, language='portuguese'):\n",
    "        if w not in stop_words:\n",
    "            filtered_text += w\n",
    "            filtered_text += ' '            \n",
    "    return filtered_text.strip()   \n",
    "    \n",
    "\n",
    "folder_integras = f'{PATH}/integras-textos'\n",
    "\n",
    "texts = {}\n",
    "for file in listdir(folder_integras):\n",
    "    if isfile(join(folder_integras, file)):\n",
    "        texts[file.split('.')[0]] = get_text_non_stop_words(get_text(join(folder_integras,file)))\n",
    "    else:\n",
    "        print('is not file', file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homologado</th>\n",
       "      <th>id</th>\n",
       "      <th>peca_promocao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>1</td>\n",
       "      <td>83031205</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>1</td>\n",
       "      <td>74959507</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7310</th>\n",
       "      <td>1</td>\n",
       "      <td>69534991</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>1</td>\n",
       "      <td>72443447</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>0</td>\n",
       "      <td>70941373</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      homologado        id peca_promocao\n",
       "3201           1  83031205          None\n",
       "6039           1  74959507          None\n",
       "7310           1  69534991          None\n",
       "2309           1  72443447          None\n",
       "6734           0  70941373          None"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# montando um DataFrame\n",
    "df_original = pd.read_json(f'{PATH}/1A.CAM.homologacao-arquivamento.json')\n",
    "df_work = df_original.copy()\n",
    "cols = ['id', 'homologado']\n",
    "df_work.drop(inplace=True, columns=[col for col in df_work.columns if col not in cols])\n",
    "df_work['peca_promocao'] = None\n",
    "df_work.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homologado</th>\n",
       "      <th>id</th>\n",
       "      <th>peca_promocao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7133</th>\n",
       "      <td>1</td>\n",
       "      <td>62431848</td>\n",
       "      <td>EXMO IC 1.14.000.000229/2014-57 Arquivamento 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>1</td>\n",
       "      <td>54520001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>1</td>\n",
       "      <td>69228152</td>\n",
       "      <td>MINISTÉRIO PÚBLICO FEDERAL PROCURADORIA DA REP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>1</td>\n",
       "      <td>69325522</td>\n",
       "      <td>Ofício Ccrim /96 NF 1.34.001.000248/2016-01 PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>1</td>\n",
       "      <td>79411018</td>\n",
       "      <td>PROCEDIMENTO PREPARATÓRIO PP Nº 1.25.006.00050...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      homologado        id                                      peca_promocao\n",
       "7133           1  62431848  EXMO IC 1.14.000.000229/2014-57 Arquivamento 0...\n",
       "3390           1  54520001                                               None\n",
       "7432           1  69228152  MINISTÉRIO PÚBLICO FEDERAL PROCURADORIA DA REP...\n",
       "7173           1  69325522  Ofício Ccrim /96 NF 1.34.001.000248/2016-01 PR...\n",
       "3845           1  79411018  PROCEDIMENTO PREPARATÓRIO PP Nº 1.25.006.00050..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Associando o texto...\n",
    "for key, text in zip(texts.keys(), texts.values()):\n",
    "    if key != '' and text != '':\n",
    "        df_work.loc[df_work.id == int(key), 'peca_promocao'] = text\n",
    "        \n",
    "df_work.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_____________________________________________________________________________________________ Inquérito Civil 1.30.012.000817/2009-09 PROMOÇÃO DE ARQUIVAMENTO Trata-se inquérito civil IC instaurado investigar possíveis irregularidades instalações alojamento estudantil Universidade Federal Rio Janeiro UFRJ Feito relatado fls 461/464 Às fls 536-538 consta Recomendação dirigida reitoria UFRJ data 25 julho 2016 visando correção várias irregularidades alojamento estudantil constatadas durante instrução procedimento Desde então tem-se adotado medidas objetivando cumprimento todos itens recomendados Contudo início mês agosto 2017 noticiada ocorrência incêndio dependências alojamento situação agravou problemas existentes Alguns alunos chegaram ficar moradia alojados provisoriamente hotel pago UFRJ O ocorrido originou instauração novo procedimento investigatório âmbito desta procuradoria República 1.30.001.004190/2017-96 recentemente apensado autos Assim presente investigação atualmente possui escopo principal acompanhar medidas vem sendo tomadas UFRJ visando amparar estudantes ficaram moradia principalmente acompanhar realização obras revitalização alojamento Nesse contexto Ministério Público Federal chamado intervir Ação Civil Pública 0192796-53.2017.4.02.51011 ajuizada Defensoria Pública União DPU face UFRJ tramita perante Seção Judiciária Estado Rio Janeiro No bojo referida ação DPU veicula seguintes pedidos 1 A cópia integral autos inserida mídia digital seguinte presente promoção arquivamento MINISTÉRIO PÚBLICO FEDERAL Procuradoria República Rio Janeiro 2 UFRJ realize prazo 30 trinta dias inspeção unidades habitacionais ALA “ B ” objetivo diagnosticar completo vícios/defeitos construção ali existentes apresentem autos minucioso relatório Vistoria além Projeto Engenharia contendo cronograma físico financeiro reconstrução todas unidades habitacionais ALA “ B ” cujas obras deverão ter início prazo 30 dias contar juntada respectivo projeto engenharia término prazo máximo 120 cento vinte dias contar início obra b UFRJ apresente prazo 30 trinta dias minucioso relatório Vistoria Projeto Engenharia contendo cronograma físico financeiro finalidade identificar tudo necessário proceder reformas todas unidades habitacionais ALA “ A ” cujos trabalhos deverão ser iniciados prazo máximo 60 sessenta dias contar relatório vistoria imposição obrigação fazer consistente execução conta própria através contratação terceiros especializados todos serviços necessários substituição esquadrias reparos forros paredes revestimentos cerâmicos instalações elétricas hidráulicas mecânicas enfim todos atos necessários colocar unidades ALA A condições habitabilidade segurança acordo normativas regência órgãos competentes fixando-lhes prazo 120 cento vinte dias execução todos serviços contar início obras c A imposição obrigação fazer consistente execução conta própria através contratação terceiros especializados todas medidas necessárias garantir segurança habitação estudantes moradores ambas Alas “ A ” “ B ” enquanto obras andamento devendo ser juntado autos processo relatório mensal execução obra cronograma relação nominal alunos universitários necessariamente deverão ausentar alojamentos enquanto durar obras d A imposição obrigação pagar quantia certa consistente pagamento bolsa/benefício aluguel temporário valor R $ 2.000,00 cada aluno condições item anterior cumpriram requisitos auxílio-moradia ausentar força incêndio realização obras ambas Alas “ A ” “ B ” durante período planejamento/execução obras entrega unidades habitacionais A cominação multa desfavor ré valor R $ 10.000,00 dez mil reais dia inércia/atraso/omissão termos art 11 Lei 7.347/85 ser revertido Fundo Federal Defesa Direitos Difusos teor dispõem art 13 Lei 7.347/85 Lei 9.008/95 Resolução CFDD 15 24/11/2004 DOU 14/12/2004 expedida Presidência Conselho Federal Gestor referido Fundo cada obrigação descumprida MINISTÉRIO PÚBLICO FEDERAL Procuradoria República Rio Janeiro 3 f A condenação ré pagamento indenização danos materiais experimentados incluindo-se danos emergentes lucros cessantes estudantes substituídos processualmente feito cuja identificação alunos ALA “ B ” valor deverão ser delimitados fase liquidação finalidade viabilizar futuras execuções individuais poderão ser entabuladas espeque arts 96 97 CDC Requer condenação pagamento indenização dano moral experimentado estudantes ser ausentar alojamentos ALA “ B ” força incêndio Por vez UFRJ defesa colacionou autos diversos documentos fim comprovar adoção medidas realização obras recuperação residência estudantil contrato firmado empresa executora relatório acerca execução contrato cronograma físico-financeiro Pois bem Diante fatos supramencionados tem-se dar continuidade presente investigação mostra inútil ineficiente considerado longo prazo tramitação procedimento grande volume documentos informações fogem contexto atual Ademais considerar âmbito judicial Ministério Público Federal atuado rigor intervenção Ação Civil Pública retromencionada primando direitos população estudantil utiliza alojamento fornecido UFRJ Já âmbito extrajudicial entendo obras melhoria vem sendo realizadas UFRJ residência estudantil melhor forma fiscalizadas meio procedimento administrativo acompanhamento cujo objetivo específico é segundo Resolução 174/2017 CNMP “ acompanhar fiscalizar forma continuada políticas públicas instituições ” inciso II art 8º Por determino extraídas cópias digitais documentos instruem ACP 0192796-53.2017.4.02.5101 instaurado Procedimento Acompanhamento PA seguinte objeto “ Acompanhar obras melhoria MINISTÉRIO PÚBLICO FEDERAL Procuradoria República Rio Janeiro 4 revitalização residência estudantil UFRJ ” Ressalta-se caso verificadas novas irregularidades bojo referido PA óbices instaurados novos procedimentos caráter investigativo Por todo exposto determino arquivamento presente inquérito civil envio autos 1ª Câmara Coordenação Revisão MPF homologação determinação providências outras entender cabíveis Comunique-se representantes acerca arquivamento fls 03 05 21 IC 1.30.001.004190/2017-96 cópia presente promoção Antes contudo certifique-se bojo destes autos acerca instauração PA acima referido inclusive identificação número procedimento Rio Janeiro 30 agosto 2018 assinado eletronicamente MARIA CRISTINA MANELLA CORDEIRO Procuradora República Rio Janeiro 30 agosto 2018'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_work['peca_promocao'][165] # só pra confirmar que as stopwords foram retiradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8267 134\n"
     ]
    }
   ],
   "source": [
    "print(len(df_work[df_work['homologado'] == 1]), len(df_work[df_work['homologado'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# removendo os sem textos de peça de promoção (problema nos dados)\n",
    "print(len(df_work[df_work['peca_promocao'].isnull()]))\n",
    "df_work.dropna(subset=['peca_promocao'], inplace=True)\n",
    "df_work.reset_index(drop=True, inplace=True)\n",
    "print(len(df_work[df_work['peca_promocao'].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6612 101\n"
     ]
    }
   ],
   "source": [
    "print(len(df_work[df_work['homologado'] == 1]), len(df_work[df_work['homologado'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando um modelo de Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5370,), (5370,), (1343,), (1343,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(df_work['peca_promocao'], df_work['homologado'], test_size=0.20, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuida-se representação anônima versando sobre possíveis irr MINISTÉRIO PÚBLICO FEDERAL PROCURADORIA DA REPÚBLICA NO DISTRITO FEDERAL 4º OFÍCIO DE ATOS ADMINISTRATIVOS Inquérito Civil 1.16.000.002107/2017-23 Promoção Arquivamento 1469/2018 Trata-se Inquérito Civil instaurado partir representação Departamento Nacional Trânsito DENATRAN relatando possível negativa Banco Brasil S.A. aceitar documentos assinados aludido órgão mediante Sistema Eletrônico Informações SEI quais somente aceitos encaminhados assinatura manual Narra representante fls 4/4v “ DENATRAN utiliza Sistema Eletrônico Informações SEI conformidade Decreto 8.539 8 outubro 2015 ” tal motivo documentos naturalmente assinados digitalmente Assim menciona tais assinaturas seguem padrão Infraestrutura Chaves Públicas Brasileira ICP-Brasil força art 6º aludido Decreto “ A autoria autenticidade integridade documentos assinatura processos administrativos eletrônicos poderão ser obtidas meio certificado digital emitido âmbito Infraestrutura Chaves Brasileira ICP-Brasil observados padrões definidos Infraestrutura ” Aduz aludida autenticidade integridade confiabilidade assinatura digital é garantida Medida Provisória MP 2.200-2/01 instituiu ICP-Brasil O artigo 10 MP1 garante documentos produzidos eletronicamente assinados digitalmente presunção veracidade 1 Art 10 Consideram-se documentos públicos particulares todos fins legais documentos eletrônicos trata Medida Provisória §1o As declarações constantes documentos forma eletrônica produzidos utilização processo certificação disponibilizado ICP-Brasil presumem-se verdadeiros relação signatários forma art 131 Lei 3.071 1º janeiro 1916 - Código Civil SGAS QUADRAS 603/604 LOTE 23 GABINETE 114 BRASÍLIA/DF CEP 70200-640 FONE 61 3313-5262 1/3 MBZ - dss PR-DF-00079699/2018 http //www.planalto.gov.br/ccivil_03/LEIS/L3071.htm # art131 http //www.planalto.gov.br/ccivil_03/LEIS/L3071.htm # art131 http //www.planalto.gov.br/ccivil_03/LEIS/L3071.htm # art131 http //www.planalto.gov.br/ccivil_03/LEIS/L3071.htm # art131 MINISTÉRIO PÚBLICO FEDERAL PROCURADORIA DA REPÚBLICA NO DISTRITO FEDERAL 4º OFÍCIO DE ATOS ADMINISTRATIVOS Menciona ademais Sistema Eletrônico Informações SEI “ possui ferramenta conferência autenticidade documentos bastando tanto interessado acesse endereço eletrônico indicado campo localizado abaixo insira código verificador código CRC informados ” Entretanto informa apesar toda regulamentação protege utilização assinatura digital denunciante “ Banco Brasil encaminhou expediente informando ofícios enviados DENATRAN deverão ser assinados manualmente ” Outrossim representante juntou autos documentos fls 5/8 dentre quais encontra-se ofício Agência Governo Federal 2017/1373 16/06/2017 encaminhado Banco Brasil informando “ todos ofícios enviados BB deverão ser assinados manualmente inclusive solicitem movimentações vinculadas Depósito Garantia ” Ademais esclarece sociedade economia mista “ Banco Brasil dispõe mecanismos garantam autenticidade assinaturas digitais ” ser sociedade economia mista estaria englobado artigo 1º Decreto 8.539/2015 estipula uso meio eletrônico apenas órgãos administração pública federal direta autárquica fundacional Para instrução autos determinou-se despacho fls 10/11 expedição ofício Banco Brasil esclarecesse fatos relatados representação O Banco Brasil respondeu fl 16 informando ainda dispunha fluxo recebimento conferência validação documentos assinados digitalmente encontrando-se desenvolvimento Informou outrossim Decreto 8.539/2015 dispõe sobre uso meio eletrônico realização processo administrativo âmbito órgãos SGAS QUADRAS 603/604 LOTE 23 GABINETE 114 BRASÍLIA/DF CEP 70200-640 FONE 61 3313-5262 2/3 MINISTÉRIO PÚBLICO FEDERAL PROCURADORIA DA REPÚBLICA NO DISTRITO FEDERAL 4º OFÍCIO DE ATOS ADMINISTRATIVOS entidades administração pública federal direta autárquica fundacional aplica sociedade economia mista tela Então fim verificar recusa parte aludida sociedade economia mista receber documentos assinados digitalmente encaminhados DENATRAN persistia determinou-se despacho fl 19 expedição ofício Departamento Nacional Trânsito DENATRAN informasse cessados óbices colocados Banco Brasil S.A. quanto recebimento documentos assinados digitalmente Resposta DENATRAN fl 21 É relatório Em resposta Departamento Nacional Trânsito DENATRAN referiu “ informamos cessaram óbices colocados Banco Brasil S.A. quanto recebimento documentos assinados digitalmente ” Assim tendo vista resposta satisfatoriamente apresentada parte Departamento Nacional Trânsito perfaz útil manutenção autos modo promovo ARQUIVAMENTO presente Inquérito Civil registros praxe submetendo-o apreciação 1ª Câmara Coordenação Revisão fins homologatórios/revisionais termos art 17 § 2º Resolução 87/2010 Conselho Superior Ministério Público Federal Antes porém comunique-se representante cientificando-o inclusive possibilidade recorrer art 17 § 1º Resolução 87/2010 CSMPF Brasília/DF 5 outubro 2018 assinado eletronicamente Marcia Brandão Zollinger Procuradora República SGAS QUADRAS 603/604 LOTE 23 GABINETE 114 BRASÍLIA/DF CEP 70200-640 FONE 61 3313-5262 3/3\n"
     ]
    }
   ],
   "source": [
    "print(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5370x82501 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2012769 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words=None)\n",
    "vect = cv.fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9828741623231572\n",
      "Precision score:  0.9850634802091113\n",
      "Recall score:  0.9977307110438729\n",
      "F1 score:  0.9913566328447951\n",
      "AUC:  0.5226748793314603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def print_score(y, preds):\n",
    "    print('Accuracy score:', accuracy_score(y, preds))\n",
    "    print('Precision score: ', format(precision_score(y, preds)))\n",
    "    print('Recall score: ', format(recall_score(y, preds)))\n",
    "    print('F1 score: ', format(f1_score(y, preds)))\n",
    "    print('AUC: ', roc_auc_score(y, preds))\n",
    "    \n",
    "print_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   20],\n",
       "       [   3, 1319]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9843633655994043\n",
      "Precision score:  0.9843633655994043\n",
      "Recall score:  1.0\n",
      "F1 score:  0.9921200750469044\n",
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "preds = nb.predict(vect.transform(X_test))\n",
    "print_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21],\n",
       "       [   0, 1322]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words com ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=None, ngram_range=(1,3)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5370x3683507 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8234254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9828741623231572\n",
      "Precision score:  0.9843400447427293\n",
      "Recall score:  0.9984871406959153\n",
      "F1 score:  0.9913631242959068\n",
      "AUC:  0.49924357034795763\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vectorized, y_train)\n",
    "\n",
    "preds = lr.predict(vect.transform(X_test))\n",
    "\n",
    "print_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21],\n",
       "       [   2, 1320]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9843633655994043\n",
      "Precision score:  0.9843633655994043\n",
      "Recall score:  1.0\n",
      "F1 score:  0.9921200750469044\n",
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "preds = nb.predict(vect.transform(X_test))\n",
    "print_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21],\n",
       "       [   0, 1322]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liberando memória\n",
    "\n",
    "%xdel vect\n",
    "%xdel X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não estou conseguindo rodar essa célula: erro de memória (rodar no Paperspace)\n",
    "\n",
    "#vect = CountVectorizer(stop_words=None, ngram_range=(1,5)).fit(X_train)\n",
    "#X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "#X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f87a84f42ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_train_vectorized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \"\"\"\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    888\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m    771\u001b[0m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[1;32m    772\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0msliced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliced\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msliced\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    492\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m            indptr)\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(min_df=1, ngram_range=(1,4)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9843633655994043\n",
      "Precision score:  0.9843633655994043\n",
      "Recall score:  1.0\n",
      "F1 score:  0.9921200750469044\n",
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vectorized, y_train)\n",
    "\n",
    "preds = lr.predict(vect.transform(X_test))\n",
    "\n",
    "print_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21],\n",
       "       [   0, 1322]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9843633655994043\n",
      "Precision score:  0.9843633655994043\n",
      "Recall score:  1.0\n",
      "F1 score:  0.9921200750469044\n",
      "AUC:  0.5\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "preds = nb.predict(vect.transform(X_test))\n",
    "print_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21],\n",
       "       [   0, 1322]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
